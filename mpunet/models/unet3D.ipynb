{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (Input, BatchNormalization, Cropping3D,\n",
    "                                     Concatenate, Conv3D, MaxPooling3D,\n",
    "                                     UpSampling3D, Reshape)\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def Unet3dFunctional(img_shape = (320,320,16,2),filters = 64, depth = 3, n_class = 3):\n",
    "    inputs = Input(shape=img_shape)\n",
    "    inp = inputs\n",
    "    residual_connections = []\n",
    "    for i in range(depth):\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                      activation='relu', padding='same')(inp)\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                      activation='relu', padding='same')(conv)\n",
    "        bn = BatchNormalization()(conv)\n",
    "        inp = MaxPooling3D(pool_size=(2,2,2))(bn)\n",
    "        filters *=2\n",
    "        residual_connections.append(bn)\n",
    "\n",
    "    conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                  activation='relu', padding='same')(inp)\n",
    "    conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                  activation='relu', padding='same')(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    for i in range(depth):\n",
    "        bn = UpSampling3D(size = (2,2,2))(bn)\n",
    "        merge = Concatenate(axis=-1)([bn, residual_connections[len(residual_connections)-i-1]])\n",
    "        filters /=2\n",
    "\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                      activation='relu', padding='same')(merge)\n",
    "\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                      activation='relu', padding='same')(conv)\n",
    "\n",
    "        bn = BatchNormalization()(conv)\n",
    "\n",
    "\n",
    "    out = Conv3D(n_class, 1, activation= 'softmax')(bn)\n",
    "\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = Unet3dFunctional(img_shape = (128,128,16,2),filters = 16, depth = 3, n_class = 2)\n",
    "model.compile(optimizer='sgd',\n",
    "                       loss = 'categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "last = model.layers[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor 'conv3d_29/Identity:0' shape=(None, 128, 128, 16, 2) dtype=float32>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last.output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/px\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/px/MultiPlanarUNet\n"
     ]
    }
   ],
   "source": [
    "%cd MultiPlanarUNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 909 # (IMPORTANT) to transform image and corresponding mask with same augmentation parameter.\n",
    "image_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 #preprocessing_function = image_preprocessing\n",
    "                                   ) # custom fuction for each image you can use resnet one too.\n",
    "mask_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 #preprocessing_function = mask_preprocessing\n",
    "                                  )  # to make mask as feedable formate (256,256,1)\n",
    "\n",
    "image_generator =image_datagen.flow_from_directory(\"data_folder/train/images/\",\n",
    "                                                    class_mode=None, seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\"data_folder/train/labels/\",\n",
    "                                                   class_mode=None, seed=seed)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagePairLoader(id=train, images=17, data_dir=/home/px/MultiPlanarUNet/data_folder/train)\n",
      "--- Image subdir: /home/px/MultiPlanarUNet/data_folder/train/images\n",
      "--- Label subdir: /home/px/MultiPlanarUNet/data_folder/train/labels\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImagePairLoader' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-69ab897386f8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmpunet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_pair_loader\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mImagePairLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mimgloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImagePairLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data_folder/train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mimgloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ImagePairLoader' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "from mpunet.image.image_pair_loader import ImagePairLoader\n",
    "imgloader = ImagePairLoader(base_dir=\"data_folder/train\")\n",
    "imgloader.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import glob\n",
    "import skimage.transform as skTrans\n",
    "\n",
    "def generate_3dimage(base_dir=\"data_folder/train\", dim = (320,320,16),\n",
    "                     batch_size = 2):\n",
    "    def loadNii(filename):\n",
    "        img = nib.load(filename)\n",
    "        data = img.get_fdata()\n",
    "        return data\n",
    "\n",
    "    image_base = os.path.join(base_dir, 'images')\n",
    "    mask_base = os.path.join(base_dir, 'labels')\n",
    "    files_names = os.listdir(image_base)\n",
    "    files_names = [i for i in files_names if not i.startswith('.')]\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_names  = np.random.choice(a = files_names, size = batch_size)\n",
    "        n_channels = 2\n",
    "        batch_x = np.empty((batch_size, *dim, n_channels))\n",
    "        batch_y = np.empty((batch_size, *dim))\n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for i, input_name in enumerate(batch_names):\n",
    "            image_path = os.path.join(image_base,input_name)\n",
    "            mask_path = os.path.join(mask_base,input_name)\n",
    "\n",
    "            input = loadNii(image_path)\n",
    "            output = loadNii(mask_path)\n",
    "            input = skTrans.resize(input, dim,\n",
    "                                   order=1, preserve_range=True)\n",
    "            output = skTrans.resize(output, dim,\n",
    "                                   order=1, preserve_range=True)\n",
    "\n",
    "\n",
    "            batch_x[i] = input\n",
    "            batch_y[i] = output\n",
    "        batch_y = np.expand_dims(batch_y, axis=-1)\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "sb = generate_3dimage(base_dir=\"data_folder/train\", batch_size = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = next(sb)\n",
    "y[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Unet3dFunctional(img_shape = (128,128,16,2),filters = 16, depth = 3, n_class = 2)\n",
    "model.compile(optimizer='sgd',\n",
    "                       loss = 'categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(sb, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import skimage.transform as skTrans\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, base_dir=\"data_folder/train\", labels=1, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        #self.labels = labels\n",
    "        self.image_base = os.path.join(base_dir, 'images')\n",
    "        self.mask_base = os.path.join(base_dir, 'labels')\n",
    "        files_names = os.listdir(self.image_base)\n",
    "        files_names = [i for i in files_names if not i.startswith('.')]\n",
    "        self.files_names = files_names\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.files_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        cur_files_names = self.files_names[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(cur_files_names)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        #self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.files_names)\n",
    "\n",
    "    def __data_generation(self, cur_files_names):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty(self.batch_size, *self.dim)\n",
    "\n",
    "        for i, input_name in enumerate(cur_files_names):\n",
    "            image_path = os.path.join(self.image_base,cur_files_names)\n",
    "            mask_path = os.path.join(self.mask_base,cur_files_names)\n",
    "\n",
    "            input = nib.load(image_path).get_fdata()\n",
    "            output = nib.load(mask_path).get_fdata()\n",
    "            input = skTrans.resize(input, *self.dim,\n",
    "                                   order=1, preserve_range=True)\n",
    "            output = skTrans.resize(output, *self.dim,\n",
    "                                   order=1, preserve_range=True)\n",
    "\n",
    "\n",
    "            X[i] = input\n",
    "            y[i] = output\n",
    "\n",
    "\n",
    "        return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(gen, (tf.dtypes.float32, tf.dtypes.int32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=sb,\n",
    "    output_types=(np.float32, np.int32),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb = DataGenerator(base_dir=\"data_folder/train\", batch_size=6, dim=(320,320,20))\n",
    "sb.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Unet3D(Model):\n",
    "    def __init__(self,original_dim,filters=64, depth=4, n_class=3,\n",
    "                 padding='same', name='auto_encoder',**kwargs):\n",
    "        super().__init__(name = name,**kwargs)\n",
    "        self.filters = filters\n",
    "        self.original_dim = original_dim\n",
    "        self.conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                  activation='relu', padding='same')\n",
    "        self.n_class = n_class\n",
    "        self.depth = depth\n",
    "    # def build(self,input_shape):\n",
    "    #     super().build(input_shape = input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inp = inputs\n",
    "        filters = self.filters\n",
    "        residual_connections = []\n",
    "        n_class = self.n_class\n",
    "        depth = self.depth\n",
    "        for i in range(4):\n",
    "            conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                          activation='relu', padding='same')(inp)\n",
    "            conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                          activation='relu', padding='same')(conv)\n",
    "            bn = BatchNormalization()(conv)\n",
    "            inp = MaxPooling3D(pool_size=(2,2,2))(bn)\n",
    "            filters *=2\n",
    "            residual_connections.append(bn)\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "              activation='relu', padding='same')(inp)\n",
    "        conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                      activation='relu', padding='same')(conv)\n",
    "        bn = BatchNormalization()(conv)\n",
    "\n",
    "        for i in range(depth):\n",
    "            bn = UpSampling3D(size = (2,2,2))(bn)\n",
    "            merge = Concatenate(axis=-1)([bn, residual_connections[len(residual_connections)-i-1]])\n",
    "            filters /=2\n",
    "\n",
    "            conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                          activation='relu', padding='same')(merge)\n",
    "\n",
    "            conv = Conv3D(filters=filters,  kernel_size= 3,\n",
    "                          activation='relu', padding='same')(conv)\n",
    "\n",
    "            bn = BatchNormalization()(conv)\n",
    "\n",
    "\n",
    "        out = Conv3D(n_class, 1, activation= 'softmax')(bn)\n",
    "        # ce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        # self.add_loss(ce_loss)\n",
    "        # self.add_metric(ce_loss, name=\"ce_loss\")\n",
    "\n",
    "        return out\n",
    "unet = Unet3D(original_dim=(224,224,224,3),filters=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unet.build((None, 224,224,224,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unet.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ = Unet3D(original_dim=(224,224,224,3))\n",
    "inputs = tf.keras.Input(shape=(224,224,224,3,))\n",
    "outputs = model_(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}